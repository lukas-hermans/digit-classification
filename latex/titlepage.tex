\title{\large Machine Learning \\ \LARGE
 Digit Classification with Kernel Perceptron}
\author{Lukas Hermans\\ \\
{Universit√† degli Studi di Milano} \\
\href{mailto:lukas.hermans@studenti.unimi.it}
{lukas.hermans@studenti.unimi.it}}

\maketitle

\begin{abstract} 
\noindent
\fontdimen2\font=0.7ex% inter word space
The MNIST database of handwritten digits is a common benchmark for the performance of machine learning algorithms for image recognition. In the present work, the multiclass kernel perceptron alorithm - an expansion of Rosenblatt's famous perceptron algorithm from 1957 - is trained for the classification of handwritten digits in the MNIST database. The database is split in $60000$ training images and $10000$ test images. Three different realizations of the multiclass kernel perceptron algorithm lead to test error rates of $\SI{100}{\percent}$, $\SI{100}{\percent}$, and $\SI{100}{\percent}$, respectively. A comparison with the literature reveals that the results are similar to the test error rates for other classical machine learning algorithms, especially the closely related support vector machine. The application of additonal data preprocessing techniques prior to the training phase as well as deep neural networks are reported to lead to significantly lower test error rates. 
\end{abstract}
